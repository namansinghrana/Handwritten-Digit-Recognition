{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a752cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c19f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44618de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "637957f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49367b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train':DataLoader(train_data,\n",
    "                         batch_size = 100,\n",
    "                         shuffle=True,\n",
    "                         num_workers=1),\n",
    "    'test': DataLoader(test_data,\n",
    "                        batch_size = 100,\n",
    "                        shuffle=False,\n",
    "                        num_workers=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc37686c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x113980f40>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x113980e50>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f7c46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440c1fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03238d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.288157\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t2.217890\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t1.569435\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t1.308788\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t1.033376\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t0.688857\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t0.805399\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t0.620284\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t0.515305\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t0.573475\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t0.503518\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t0.404291\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t0.599313\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t0.672687\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t0.533992\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t0.495563\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t0.383552\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t0.201115\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t0.481805\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t0.288076\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t0.670137\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t0.459586\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t0.405304\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t0.542906\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t0.425180\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t0.366144\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t0.436799\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t0.644679\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t0.317504\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t0.285660\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 9603/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\t0.430132\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t0.262317\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t0.345388\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t0.185096\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t0.247224\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t0.185897\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t0.344710\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t0.373388\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t0.320662\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t0.348469\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t0.274964\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t0.260625\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t0.279917\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t0.230425\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t0.290788\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t0.222285\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t0.292619\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t0.247799\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t0.251648\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t0.363894\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t0.204583\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t0.254361\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t0.307936\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t0.247167\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t0.308974\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t0.135835\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t0.252633\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t0.218830\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t0.219459\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t0.189208\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 9719/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\t0.162891\n",
      "Train Epoch: 3 [2000/60000 (3%)]\t0.201020\n",
      "Train Epoch: 3 [4000/60000 (7%)]\t0.323714\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t0.282638\n",
      "Train Epoch: 3 [8000/60000 (13%)]\t0.294836\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t0.217690\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t0.187329\n",
      "Train Epoch: 3 [14000/60000 (23%)]\t0.335521\n",
      "Train Epoch: 3 [16000/60000 (27%)]\t0.277761\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t0.171393\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t0.246608\n",
      "Train Epoch: 3 [22000/60000 (37%)]\t0.151666\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t0.295929\n",
      "Train Epoch: 3 [26000/60000 (43%)]\t0.227342\n",
      "Train Epoch: 3 [28000/60000 (47%)]\t0.173045\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t0.359681\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t0.158918\n",
      "Train Epoch: 3 [34000/60000 (57%)]\t0.237568\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t0.274463\n",
      "Train Epoch: 3 [38000/60000 (63%)]\t0.153823\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t0.251661\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t0.248031\n",
      "Train Epoch: 3 [44000/60000 (73%)]\t0.156466\n",
      "Train Epoch: 3 [46000/60000 (77%)]\t0.284258\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t0.241928\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t0.220602\n",
      "Train Epoch: 3 [52000/60000 (87%)]\t0.284302\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t0.139483\n",
      "Train Epoch: 3 [56000/60000 (93%)]\t0.149147\n",
      "Train Epoch: 3 [58000/60000 (97%)]\t0.180892\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9779/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\t0.182871\n",
      "Train Epoch: 4 [2000/60000 (3%)]\t0.388325\n",
      "Train Epoch: 4 [4000/60000 (7%)]\t0.247596\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t0.162794\n",
      "Train Epoch: 4 [8000/60000 (13%)]\t0.284096\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t0.104351\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t0.083124\n",
      "Train Epoch: 4 [14000/60000 (23%)]\t0.183940\n",
      "Train Epoch: 4 [16000/60000 (27%)]\t0.219296\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t0.137880\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t0.211749\n",
      "Train Epoch: 4 [22000/60000 (37%)]\t0.424759\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t0.124695\n",
      "Train Epoch: 4 [26000/60000 (43%)]\t0.155996\n",
      "Train Epoch: 4 [28000/60000 (47%)]\t0.104278\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t0.243541\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t0.094601\n",
      "Train Epoch: 4 [34000/60000 (57%)]\t0.138987\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t0.183039\n",
      "Train Epoch: 4 [38000/60000 (63%)]\t0.088197\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t0.092718\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t0.149121\n",
      "Train Epoch: 4 [44000/60000 (73%)]\t0.123083\n",
      "Train Epoch: 4 [46000/60000 (77%)]\t0.253787\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t0.206676\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t0.147806\n",
      "Train Epoch: 4 [52000/60000 (87%)]\t0.090451\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t0.253519\n",
      "Train Epoch: 4 [56000/60000 (93%)]\t0.102470\n",
      "Train Epoch: 4 [58000/60000 (97%)]\t0.118070\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9804/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\t0.146756\n",
      "Train Epoch: 5 [2000/60000 (3%)]\t0.210973\n",
      "Train Epoch: 5 [4000/60000 (7%)]\t0.128689\n",
      "Train Epoch: 5 [6000/60000 (10%)]\t0.229251\n",
      "Train Epoch: 5 [8000/60000 (13%)]\t0.117529\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t0.221271\n",
      "Train Epoch: 5 [12000/60000 (20%)]\t0.101011\n",
      "Train Epoch: 5 [14000/60000 (23%)]\t0.249848\n",
      "Train Epoch: 5 [16000/60000 (27%)]\t0.217283\n",
      "Train Epoch: 5 [18000/60000 (30%)]\t0.259088\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t0.153335\n",
      "Train Epoch: 5 [22000/60000 (37%)]\t0.223407\n",
      "Train Epoch: 5 [24000/60000 (40%)]\t0.190411\n",
      "Train Epoch: 5 [26000/60000 (43%)]\t0.164828\n",
      "Train Epoch: 5 [28000/60000 (47%)]\t0.113202\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t0.334293\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t0.168637\n",
      "Train Epoch: 5 [34000/60000 (57%)]\t0.123487\n",
      "Train Epoch: 5 [36000/60000 (60%)]\t0.181517\n",
      "Train Epoch: 5 [38000/60000 (63%)]\t0.175041\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t0.191096\n",
      "Train Epoch: 5 [42000/60000 (70%)]\t0.106394\n",
      "Train Epoch: 5 [44000/60000 (73%)]\t0.118335\n",
      "Train Epoch: 5 [46000/60000 (77%)]\t0.206078\n",
      "Train Epoch: 5 [48000/60000 (80%)]\t0.176754\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t0.145185\n",
      "Train Epoch: 5 [52000/60000 (87%)]\t0.158554\n",
      "Train Epoch: 5 [54000/60000 (90%)]\t0.160721\n",
      "Train Epoch: 5 [56000/60000 (93%)]\t0.139985\n",
      "Train Epoch: 5 [58000/60000 (97%)]\t0.257239\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9807/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\t0.145600\n",
      "Train Epoch: 6 [2000/60000 (3%)]\t0.260952\n",
      "Train Epoch: 6 [4000/60000 (7%)]\t0.159143\n",
      "Train Epoch: 6 [6000/60000 (10%)]\t0.310849\n",
      "Train Epoch: 6 [8000/60000 (13%)]\t0.131697\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t0.154983\n",
      "Train Epoch: 6 [12000/60000 (20%)]\t0.160362\n",
      "Train Epoch: 6 [14000/60000 (23%)]\t0.302764\n",
      "Train Epoch: 6 [16000/60000 (27%)]\t0.179356\n",
      "Train Epoch: 6 [18000/60000 (30%)]\t0.221427\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t0.116431\n",
      "Train Epoch: 6 [22000/60000 (37%)]\t0.110189\n",
      "Train Epoch: 6 [24000/60000 (40%)]\t0.099561\n",
      "Train Epoch: 6 [26000/60000 (43%)]\t0.110932\n",
      "Train Epoch: 6 [28000/60000 (47%)]\t0.224396\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t0.175292\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t0.277351\n",
      "Train Epoch: 6 [34000/60000 (57%)]\t0.062401\n",
      "Train Epoch: 6 [36000/60000 (60%)]\t0.218078\n",
      "Train Epoch: 6 [38000/60000 (63%)]\t0.220269\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t0.171949\n",
      "Train Epoch: 6 [42000/60000 (70%)]\t0.134089\n",
      "Train Epoch: 6 [44000/60000 (73%)]\t0.172450\n",
      "Train Epoch: 6 [46000/60000 (77%)]\t0.454746\n",
      "Train Epoch: 6 [48000/60000 (80%)]\t0.158421\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t0.144537\n",
      "Train Epoch: 6 [52000/60000 (87%)]\t0.117291\n",
      "Train Epoch: 6 [54000/60000 (90%)]\t0.084232\n",
      "Train Epoch: 6 [56000/60000 (93%)]\t0.235975\n",
      "Train Epoch: 6 [58000/60000 (97%)]\t0.166380\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9843/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\t0.137758\n",
      "Train Epoch: 7 [2000/60000 (3%)]\t0.218003\n",
      "Train Epoch: 7 [4000/60000 (7%)]\t0.206405\n",
      "Train Epoch: 7 [6000/60000 (10%)]\t0.166167\n",
      "Train Epoch: 7 [8000/60000 (13%)]\t0.164910\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t0.108202\n",
      "Train Epoch: 7 [12000/60000 (20%)]\t0.130616\n",
      "Train Epoch: 7 [14000/60000 (23%)]\t0.212828\n",
      "Train Epoch: 7 [16000/60000 (27%)]\t0.253669\n",
      "Train Epoch: 7 [18000/60000 (30%)]\t0.137119\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t0.087235\n",
      "Train Epoch: 7 [22000/60000 (37%)]\t0.287963\n",
      "Train Epoch: 7 [24000/60000 (40%)]\t0.147897\n",
      "Train Epoch: 7 [26000/60000 (43%)]\t0.067862\n",
      "Train Epoch: 7 [28000/60000 (47%)]\t0.185022\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t0.141416\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t0.221219\n",
      "Train Epoch: 7 [34000/60000 (57%)]\t0.177096\n",
      "Train Epoch: 7 [36000/60000 (60%)]\t0.118528\n",
      "Train Epoch: 7 [38000/60000 (63%)]\t0.114558\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t0.153354\n",
      "Train Epoch: 7 [42000/60000 (70%)]\t0.216134\n",
      "Train Epoch: 7 [44000/60000 (73%)]\t0.202227\n",
      "Train Epoch: 7 [46000/60000 (77%)]\t0.201079\n",
      "Train Epoch: 7 [48000/60000 (80%)]\t0.096470\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t0.246552\n",
      "Train Epoch: 7 [52000/60000 (87%)]\t0.155675\n",
      "Train Epoch: 7 [54000/60000 (90%)]\t0.172611\n",
      "Train Epoch: 7 [56000/60000 (93%)]\t0.163221\n",
      "Train Epoch: 7 [58000/60000 (97%)]\t0.156495\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9853/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\t0.118430\n",
      "Train Epoch: 8 [2000/60000 (3%)]\t0.140176\n",
      "Train Epoch: 8 [4000/60000 (7%)]\t0.205100\n",
      "Train Epoch: 8 [6000/60000 (10%)]\t0.072787\n",
      "Train Epoch: 8 [8000/60000 (13%)]\t0.181574\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t0.199866\n",
      "Train Epoch: 8 [12000/60000 (20%)]\t0.156056\n",
      "Train Epoch: 8 [14000/60000 (23%)]\t0.169294\n",
      "Train Epoch: 8 [16000/60000 (27%)]\t0.092899\n",
      "Train Epoch: 8 [18000/60000 (30%)]\t0.350202\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t0.162738\n",
      "Train Epoch: 8 [22000/60000 (37%)]\t0.092248\n",
      "Train Epoch: 8 [24000/60000 (40%)]\t0.187919\n",
      "Train Epoch: 8 [26000/60000 (43%)]\t0.056548\n",
      "Train Epoch: 8 [28000/60000 (47%)]\t0.210561\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t0.191947\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t0.084512\n",
      "Train Epoch: 8 [34000/60000 (57%)]\t0.196836\n",
      "Train Epoch: 8 [36000/60000 (60%)]\t0.108836\n",
      "Train Epoch: 8 [38000/60000 (63%)]\t0.261709\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t0.091782\n",
      "Train Epoch: 8 [42000/60000 (70%)]\t0.139150\n",
      "Train Epoch: 8 [44000/60000 (73%)]\t0.224540\n",
      "Train Epoch: 8 [46000/60000 (77%)]\t0.204116\n",
      "Train Epoch: 8 [48000/60000 (80%)]\t0.100286\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t0.237191\n",
      "Train Epoch: 8 [52000/60000 (87%)]\t0.211156\n",
      "Train Epoch: 8 [54000/60000 (90%)]\t0.237069\n",
      "Train Epoch: 8 [56000/60000 (93%)]\t0.030896\n",
      "Train Epoch: 8 [58000/60000 (97%)]\t0.364935\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9852/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\t0.074408\n",
      "Train Epoch: 9 [2000/60000 (3%)]\t0.115286\n",
      "Train Epoch: 9 [4000/60000 (7%)]\t0.096883\n",
      "Train Epoch: 9 [6000/60000 (10%)]\t0.138267\n",
      "Train Epoch: 9 [8000/60000 (13%)]\t0.078369\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t0.197860\n",
      "Train Epoch: 9 [12000/60000 (20%)]\t0.097202\n",
      "Train Epoch: 9 [14000/60000 (23%)]\t0.125348\n",
      "Train Epoch: 9 [16000/60000 (27%)]\t0.056226\n",
      "Train Epoch: 9 [18000/60000 (30%)]\t0.100485\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t0.177906\n",
      "Train Epoch: 9 [22000/60000 (37%)]\t0.163348\n",
      "Train Epoch: 9 [24000/60000 (40%)]\t0.082725\n",
      "Train Epoch: 9 [26000/60000 (43%)]\t0.230505\n",
      "Train Epoch: 9 [28000/60000 (47%)]\t0.102930\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t0.230001\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t0.113830\n",
      "Train Epoch: 9 [34000/60000 (57%)]\t0.160767\n",
      "Train Epoch: 9 [36000/60000 (60%)]\t0.141996\n",
      "Train Epoch: 9 [38000/60000 (63%)]\t0.185316\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t0.072143\n",
      "Train Epoch: 9 [42000/60000 (70%)]\t0.157811\n",
      "Train Epoch: 9 [44000/60000 (73%)]\t0.093162\n",
      "Train Epoch: 9 [46000/60000 (77%)]\t0.263568\n",
      "Train Epoch: 9 [48000/60000 (80%)]\t0.135398\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t0.115804\n",
      "Train Epoch: 9 [52000/60000 (87%)]\t0.080575\n",
      "Train Epoch: 9 [54000/60000 (90%)]\t0.111803\n",
      "Train Epoch: 9 [56000/60000 (93%)]\t0.121869\n",
      "Train Epoch: 9 [58000/60000 (97%)]\t0.151843\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 9876/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\t0.160274\n",
      "Train Epoch: 10 [2000/60000 (3%)]\t0.238162\n",
      "Train Epoch: 10 [4000/60000 (7%)]\t0.124956\n",
      "Train Epoch: 10 [6000/60000 (10%)]\t0.161889\n",
      "Train Epoch: 10 [8000/60000 (13%)]\t0.131915\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t0.070563\n",
      "Train Epoch: 10 [12000/60000 (20%)]\t0.178066\n",
      "Train Epoch: 10 [14000/60000 (23%)]\t0.125947\n",
      "Train Epoch: 10 [16000/60000 (27%)]\t0.081061\n",
      "Train Epoch: 10 [18000/60000 (30%)]\t0.050634\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t0.180982\n",
      "Train Epoch: 10 [22000/60000 (37%)]\t0.060377\n",
      "Train Epoch: 10 [24000/60000 (40%)]\t0.117442\n",
      "Train Epoch: 10 [26000/60000 (43%)]\t0.151968\n",
      "Train Epoch: 10 [28000/60000 (47%)]\t0.287663\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t0.160188\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t0.056748\n",
      "Train Epoch: 10 [34000/60000 (57%)]\t0.145869\n",
      "Train Epoch: 10 [36000/60000 (60%)]\t0.157557\n",
      "Train Epoch: 10 [38000/60000 (63%)]\t0.066503\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t0.128884\n",
      "Train Epoch: 10 [42000/60000 (70%)]\t0.174564\n",
      "Train Epoch: 10 [44000/60000 (73%)]\t0.172096\n",
      "Train Epoch: 10 [46000/60000 (77%)]\t0.066631\n",
      "Train Epoch: 10 [48000/60000 (80%)]\t0.076612\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t0.141313\n",
      "Train Epoch: 10 [52000/60000 (87%)]\t0.120806\n",
      "Train Epoch: 10 [54000/60000 (90%)]\t0.147962\n",
      "Train Epoch: 10 [56000/60000 (93%)]\t0.332190\n",
      "Train Epoch: 10 [58000/60000 (97%)]\t0.131489\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 9884/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e09633a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query label: 7\n",
      "Nearest labels: [7 7 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "# After training is complete, extract features and build FAISS index\n",
    "# (Run this cell after all epochs are finished)\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Optimized feature extraction: minimal memory, clear variables\n",
    "\n",
    "def extract_features(model, loader, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data = data.to(device)\n",
    "            # Forward pass up to the penultimate layer\n",
    "            x = F.relu(F.max_pool2d(model.conv1(data), 2))\n",
    "            x = F.relu(F.max_pool2d(model.conv2_drop(model.conv2(x)), 2))\n",
    "            x = x.view(-1, 320)\n",
    "            x = F.relu(model.fc1(x))\n",
    "            features.append(x.cpu().numpy())\n",
    "            labels.append(target.cpu().numpy())\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels\n",
    "\n",
    "# Use the first 20 test images, batch size 2\n",
    "larger_test_loader = DataLoader(Subset(test_data, range(20)), batch_size=2, shuffle=False)\n",
    "\n",
    "# Clear previous variables to free memory\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "features, labels = extract_features(model, larger_test_loader, device)\n",
    "\n",
    "index = faiss.IndexFlatL2(features.shape[1])\n",
    "index.add(features)\n",
    "\n",
    "query = features[0].reshape(1, -1)\n",
    "D, I = index.search(query, k=5)\n",
    "print('Query label:', labels[0])\n",
    "print('Nearest labels:', labels[I[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5a8ca6",
   "metadata": {},
   "source": [
    "## Step 1: Attach Captions to Images\n",
    "For each image, we will create a simple caption (e.g., \"Digit 7\"). This will be used as context for the generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e2a689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Handwritten digit: 7', 'Handwritten digit: 2', 'Handwritten digit: 1', 'Handwritten digit: 0', 'Handwritten digit: 4']\n"
     ]
    }
   ],
   "source": [
    "# Create captions for the first N test images (e.g., 20)\n",
    "num_caption_images = 20\n",
    "test_captions = [f\"Handwritten digit: {test_data[i][1]}\" for i in range(num_caption_images)]\n",
    "print(test_captions[:5])  # Show a few example captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2067f0e",
   "metadata": {},
   "source": [
    "## Step 1 (Multilingual): Attach Multilingual Captions to Images\n",
    "We will add captions in multiple languages for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e2af604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'en': 'Handwritten digit: 7', 'hi': 'हस्तलिखित अंक: 7', 'es': 'Dígito escrito a mano: 7'}, {'en': 'Handwritten digit: 2', 'hi': 'हस्तलिखित अंक: 2', 'es': 'Dígito escrito a mano: 2'}]\n"
     ]
    }
   ],
   "source": [
    "# Example: Add multilingual captions for the first N test images\n",
    "num_caption_images = 20\n",
    "test_captions_multilingual = []\n",
    "for i in range(num_caption_images):\n",
    "    label = test_data[i][1]\n",
    "    captions = {\n",
    "        'en': f'Handwritten digit: {label}',\n",
    "        'hi': f'हस्तलिखित अंक: {label}',\n",
    "        'es': f'Dígito escrito a mano: {label}'\n",
    "    }\n",
    "    test_captions_multilingual.append(captions)\n",
    "print(test_captions_multilingual[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fbe31d",
   "metadata": {},
   "source": [
    "### Output Example: Multilingual Captions\n",
    "The cell above prints the first two multilingual caption dictionaries, showing the format for English, Hindi, and Spanish. This helps verify that captions are correctly generated for each language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b07376",
   "metadata": {},
   "source": [
    "## Step 2: Retrieval Pipeline\n",
    "We will use the FAISS index to retrieve the top-k similar images for a given query image, and collect their captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fc58157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query caption: Handwritten digit: 7\n",
      "Retrieved captions: ['Handwritten digit: 7', 'Handwritten digit: 7', 'Handwritten digit: 9', 'Handwritten digit: 9', 'Handwritten digit: 9']\n"
     ]
    }
   ],
   "source": [
    "# Example: Retrieve top-k similar images and their captions for a query image\n",
    "k = 5\n",
    "query_idx = 0  # Use the first image as the query\n",
    "query_feature = features[query_idx].reshape(1, -1)\n",
    "D, I = index.search(query_feature, k)\n",
    "retrieved_indices = I[0]\n",
    "retrieved_captions = [test_captions[i] for i in retrieved_indices]\n",
    "print(\"Query caption:\", test_captions[query_idx])\n",
    "print(\"Retrieved captions:\", retrieved_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e027d659",
   "metadata": {},
   "source": [
    "## Step 2 (Multilingual): Retrieval Pipeline with Multilingual Captions\n",
    "Retrieve top-k similar images and their captions in the desired language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "804d681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query caption: हस्तलिखित अंक: 7\n",
      "Retrieved captions: ['हस्तलिखित अंक: 7', 'हस्तलिखित अंक: 7', 'हस्तलिखित अंक: 9', 'हस्तलिखित अंक: 9', 'हस्तलिखित अंक: 9']\n"
     ]
    }
   ],
   "source": [
    "# Set the desired language for retrieval and generation\n",
    "lang = 'hi'  # 'en', 'hi', or 'es'\n",
    "\n",
    "# Retrieve captions in the selected language\n",
    "retrieved_captions_multilingual = [test_captions_multilingual[i][lang] for i in retrieved_indices]\n",
    "print(\"Query caption:\", test_captions_multilingual[query_idx][lang])\n",
    "print(\"Retrieved captions:\", retrieved_captions_multilingual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a952fd",
   "metadata": {},
   "source": [
    "## Step 3: Generative Model Integration\n",
    "We will use a small Hugging Face model (e.g., T5-small) to generate a response based on the retrieved captions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea69efed",
   "metadata": {},
   "source": [
    "## Step 3 (Multilingual): Multilingual Generative Model Integration\n",
    "Use a multilingual generative model (e.g., mT5 or mBART) to generate a response in the selected language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66bc5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namansinghrana/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/namansinghrana/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Converting from SentencePiece and Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast converters: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tiktoken/load.py:168\u001b[0m, in \u001b[0;36mload_tiktoken_bpe\u001b[0;34m(tiktoken_bpe_file, expected_hash)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     token, rank \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m    169\u001b[0m     ret[base64\u001b[38;5;241m.\u001b[39mb64decode(token)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(rank)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/convert_slow_tokenizer.py:1864\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1863\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from Tiktoken\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1864\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTikTokenConverter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/convert_slow_tokenizer.py:1679\u001b[0m, in \u001b[0;36mTikTokenConverter.converted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconverted\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tokenizer:\n\u001b[0;32m-> 1679\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1680\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mpre_tokenizer \u001b[38;5;241m=\u001b[39m pre_tokenizers\u001b[38;5;241m.\u001b[39mSequence(\n\u001b[1;32m   1681\u001b[0m         [\n\u001b[1;32m   1682\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mSplit(Regex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern), behavior\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misolated\u001b[39m\u001b[38;5;124m\"\u001b[39m, invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1683\u001b[0m             pre_tokenizers\u001b[38;5;241m.\u001b[39mByteLevel(add_prefix_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space, use_regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1684\u001b[0m         ]\n\u001b[1;32m   1685\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/convert_slow_tokenizer.py:1672\u001b[0m, in \u001b[0;36mTikTokenConverter.tokenizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1672\u001b[0m     vocab_scores, merges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_vocab_merges_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1673\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(BPE(vocab_scores, merges, fuse_unk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/convert_slow_tokenizer.py:1648\u001b[0m, in \u001b[0;36mTikTokenConverter.extract_vocab_merges_from_model\u001b[0;34m(self, tiktoken_url)\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1645\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tiktoken` is required to read a `tiktoken` file. Install it with `pip install tiktoken`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1646\u001b[0m     )\n\u001b[0;32m-> 1648\u001b[0m bpe_ranks \u001b[38;5;241m=\u001b[39m \u001b[43mload_tiktoken_bpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtiktoken_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1649\u001b[0m byte_encoder \u001b[38;5;241m=\u001b[39m bytes_to_unicode()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tiktoken/load.py:171\u001b[0m, in \u001b[0;36mload_tiktoken_bpe\u001b[0;34m(tiktoken_bpe_file, expected_hash)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError parsing line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtiktoken_bpe_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mValueError\u001b[0m: Error parsing line b'\\x0e' in /Users/namansinghrana/.cache/huggingface/hub/models--google--mt5-small/snapshots/73fb5dbe4756edadc8fbe8c769b0a109493acf7a/spiece.model",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Use a multilingual model (mT5-small) for text2text-generation\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m generator_multi \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext2text-generation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgoogle/mt5-small\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Prepare the prompt in the selected language\u001b[39;00m\n\u001b[1;32m     15\u001b[0m prompt_multi \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mप्रश्न: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_captions_multilingual[query_idx][lang]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mसमान उदाहरण: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(retrieved_captions_multilingual) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mसारांश:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPregunta: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_captions_multilingual[query_idx][lang]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEjemplos similares: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(retrieved_captions_multilingual) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResumen:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_captions_multilingual[query_idx][lang]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSimilar examples: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(retrieved_captions_multilingual) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSummary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/__init__.py:1078\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m load_tokenizer:\n\u001b[0;32m-> 1078\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1080\u001b[0m         tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/__init__.py:1073\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m             tokenizer_kwargs \u001b[38;5;241m=\u001b[39m model_kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   1071\u001b[0m             tokenizer_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), tokenizer_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1073\u001b[0m         tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m load_tokenizer:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/auto/tokenization_auto.py:1156\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1154\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1155\u001b[0m         )\n\u001b[0;32m-> 1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:2113\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2111\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2116\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2117\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:2359\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2359\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2360\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n\u001b[1;32m   2361\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2364\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/t5/tokenization_t5_fast.py:119\u001b[0m, in \u001b[0;36mT5TokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, eos_token, unk_token, pad_token, extra_ids, additional_special_tokens, add_prefix_space, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_slow\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_prefix_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_prefix_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m vocab_file\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_ids \u001b[38;5;241m=\u001b[39m extra_ids\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_fast.py:139\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_special_tokens \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional_special_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m--> 139\u001b[0m     fast_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_slow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tiktoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     slow_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/convert_slow_tokenizer.py:1869\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer, from_tiktoken)\u001b[0m\n\u001b[1;32m   1864\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TikTokenConverter(\n\u001b[1;32m   1865\u001b[0m         vocab_file\u001b[38;5;241m=\u001b[39mtransformer_tokenizer\u001b[38;5;241m.\u001b[39mvocab_file,\n\u001b[1;32m   1866\u001b[0m         additional_special_tokens\u001b[38;5;241m=\u001b[39mtransformer_tokenizer\u001b[38;5;241m.\u001b[39madditional_special_tokens,\n\u001b[1;32m   1867\u001b[0m     )\u001b[38;5;241m.\u001b[39mconverted()\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1870\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting from SentencePiece and Tiktoken failed, if a converter for SentencePiece is available, provide a model path \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1871\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a SentencePiece tokenizer.model file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1872\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently available slow->fast converters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(SLOW_TO_FAST_CONVERTERS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1873\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Converting from SentencePiece and Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast converters: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']"
     ]
    }
   ],
   "source": [
    "# Install missing dependencies for transformers\n",
    "%pip install tiktoken protobuf --quiet\n",
    "\n",
    "# Install and use a multilingual text generation model (e.g., mT5-small)\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "except ImportError:\n",
    "    %pip install transformers --quiet\n",
    "    from transformers import pipeline\n",
    "\n",
    "# Use a multilingual model (mT5-small) for text2text-generation\n",
    "generator_multi = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
    "\n",
    "# Prepare the prompt in the selected language\n",
    "prompt_multi = f\"प्रश्न: {test_captions_multilingual[query_idx][lang]}\\nसमान उदाहरण: \" + \", \".join(retrieved_captions_multilingual) + \"\\nसारांश:\" if lang == 'hi' else (f\"Pregunta: {test_captions_multilingual[query_idx][lang]}\\nEjemplos similares: \" + \", \".join(retrieved_captions_multilingual) + \"\\nResumen:\" if lang == 'es' else f\"Question: {test_captions_multilingual[query_idx][lang]}\\nSimilar examples: \" + \", \".join(retrieved_captions_multilingual) + \"\\nSummary:\")\n",
    "\n",
    "# Generate a response in the selected language\n",
    "response_multi = generator_multi(prompt_multi, max_length=50, num_return_sequences=1)[0]['generated_text']\n",
    "print(f\"Generated response in {lang}:\\n\", response_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e68b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install transformers if not already installed\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "except ImportError:\n",
    "    %pip install transformers --quiet\n",
    "    from transformers import pipeline\n",
    "\n",
    "# Use a small text generation model (T5-small or DistilGPT-2)\n",
    "generator = pipeline('text-generation', model='distilgpt2')\n",
    "\n",
    "# Prepare the prompt for the generative model\n",
    "prompt = f\"Query: {test_captions[query_idx]}\\nSimilar examples: \" + \", \".join(retrieved_captions) + \"\\nSummary:\"\n",
    "\n",
    "# Generate a response\n",
    "response = generator(prompt, max_length=50, num_return_sequences=1)[0]['generated_text']\n",
    "print(\"Generated response:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a7efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[1]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "print(f'Predicted Label: {pred}')\n",
    "\n",
    "image = data.squeeze().cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
